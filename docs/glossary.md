# Glossary

This document contains definitions of key terms and concepts used throughout the Sirius project.

## Navigation

[A](#a) | [B](#b) | [C](#c) | [D](#d) | [E](#e) | [F](#f) | [G](#g) | [H](#h) | [I](#i) | [J](#j) | [K](#k) | [L](#l) | [M](#m) | [N](#n) | [O](#o) | [P](#p) | [Q](#q) | [R](#r) | [S](#s) | [T](#t) | [U](#u) | [V](#v) | [W](#w) | [X](#x) | [Y](#y) | [Z](#z)

## A

## B

## C

## D

**Data Batch** - A Data Wrapper in Sirius for input and output of a pipeline. It can be a wrapper of cudf::table (for pipeline output) or spilling::allocation (for downgrade output).

**Data Repository** - A container for Data Batches where all Scan Executors and Pipeline Executor tasks get output to. Data in the repository can have its underlying source of data moved between memory tiers. A Data Batch that is associated with a Pipeline Task/Downgrade Task will be removed from the Data Repository (a Data Batch only exist in a Data Repository in between pipeline).

**Downgrade Executor** - A module that owns a local thread pool which will operate on a Downgrade Task by copying a Data Batch associated with it from GPU to CPU.

**Downgrade Task** - A task that consists of a Data Batch whose memory resides in GPU that we are going to move to CPU.

**Downgrade Task Creator** - A thread which will iterate through Data Repository and Pipeline Task Queue to decide which Data Batch to downgrade in a Data Repository. It will then create a Downgrade Task and push it into the Downgrade Task Queue

**Downgrade Task Queue** - A task queue that stores Downgrade Tasks before it's being executed by the Downgrade Executor.

**Downgrade Thread Pool** - A pool of threads that exist in downgrade executor and are used to copy Data Batch from GPU to CPU.

## E

## F

## G

**GPU Allocator** - A wrapper around RMM to allocate GPU memory.

**GPU Scheduling Thread** - A thread which has a stream associated with it and can be used to execute tasks on a GPU. It pulls from the pipeline queue in order to get tasks to process.

**GPU Thread Pool** - A pool of GPU Scheduling threads that exist in the pipeline executor and are used to process tasks as they are added to the queue. The number of threads here define the parallelism of gpu compute.

## H

## I

## J

## K

**Kernel** - A CUDA compute kernel.

## L

## M

**Memory Reservation** - A lease on memory. It means you are expected to be consuming that amount of memory during your execution.

**Memory Reservation Manager** - A module that can give memory reservations into one or more memory tiers. Its purpose is to be able to block executing threads from proceeding when the reservations are full utilized (to prevent too many tasks running at the same time).

**Memory Resource Tracker** - A resource tracker which tracks the memory that has been allocated so far in a particular Pipeline Task.

## N

## O

**Operators** - Parts of the physical plan that are used to build a pipeline. Operators that can be pipelined are used to create a pipeline that then gets wrapped into a task and executed.

## P

**Pipeline** - A way of describing the transformations that a task is going to be applying to input data. It is built up by chaining the execute method of multiple operators together. Pipelines and dependencies across pipelines in a query plan is generated by DuckDB.

**Pipeline Executor** - A module that owns a local thread pool that uses GPU (via libcudf API) to execute all the operators in a Pipeline Task.

**Pipeline Task** - A task which will be executed by the pipeline executor. The task consists of a set of operators in a pipeline (generated by DuckDB) with a DataBatch associated with it. After a Pipeline Task is done, the output data batch will be pushed into the Data Repository and a Task Completion Message will be submitted to Task Completion Message Queue.

**Pipeline Task Queue** - A task queue that stores Pipeline Tasks that are going to be processed on the GPU by Sirius using the Pipeline executor. All Pipeline executor tasks are added to this queue for execution by the operators.

**Pipeline Metadata Hash Map** - A global data structure (hash map) that stores the logical plan and DuckDB pipeline information.

## Q

## R

## S

**Scan Executor** - A module that uses DuckDB to scan data from sources and push into the Data Repository.

**Scan Task** - A task which will be executed by the scan executor. After a Scan Task is done, the data batch will be pushed into the Data Repository and a Task Completion Message will be submitted to Task Completion Message Queue.

**Scan Task Queue** - A Task Queue which uses the regular DuckDB execution model for storing tasks related to scanning data into the system.

## T

**Task Creator** - A thread that (1) poll the task completion message queue, (1) create Scan Tasks and pushed them into the Scan Task Queue, (2) iterates through Data Repository and creates Pipeline Tasks and pushed them into the Pipeline Task Queue. The Task Creator also keep tracks of when the query has finished.

**Task Completion Message Queue** - A message queue that stores the Task Completion Message from Scan Executor and Pipeline Executor.

**Thread Coordinator** - The main thread running Sirius extension on DuckDB. The thread coordinator will pass the logical plan information from DuckDB to the Pipeline Metadata Hash Map and signal Task Creator to start creating tasks.

## U

## V

## W

## X

## Y

## Z

---


# Glossary

This document contains definitions of key terms and concepts used throughout the Sirius project.

## Navigation

[A](#a) | [B](#b) | [C](#c) | [D](#d) | [E](#e) | [F](#f) | [G](#g) | [H](#h) | [I](#i) | [J](#j) | [K](#k) | [L](#l) | [M](#m) | [N](#n) | [O](#o) | [P](#p) | [Q](#q) | [R](#r) | [S](#s) | [T](#t) | [U](#u) | [V](#v) | [W](#w) | [X](#x) | [Y](#y) | [Z](#z)

## A

## B

## C

## D

**Data Batch** - A Data Wrapper in Sirius for input and output of a pipeline. It can be a wrapper of cudf::table (for pipeline output) or spilling::allocation (for downgrade output).

**Data Repository** - A container for Data Batches where all Scan Executors and Pipeline Executor tasks get output to. Data in the repository can have its underlying source of data moved between memory tiers. A Data Batch that is associated with a Pipeline Task will be removed from the Data Repository (a Data Batch only exist in a Data Repository in between pipeline).

**Downgrade Executor** - A module that owns a local thread pool which will operate on a Downgrade Task by copying a Data Batch associated with it from GPU to CPU.

**Downgrade Task** - A task that consists of a Data Batch whose memory resides in GPU that we are going to move to CPU.

**Downgrade Task Queue** - A task queue that stores Downgrade Tasks before it's being executed by the Downgrade Executor.

**Downgrade Thread Pool** - A pool of threads that exist in downgrade executor and are used to copy Data Batch from GPU to CPU.

## E

## F

## G

**GPU Allocator** - A wrapper around RMM to allocate GPU memory.

**GPU Memory Manager** - A module which will decide which Data Batch to downgrade in a Data Repository.

**GPU Scheduling Thread** - A thread which has a stream associated with it and can be used to execute tasks on a GPU. It pulls from the pipeline queue in order to get tasks to process.

**GPU Thread Pool** - A pool of GPU Scheduling threads that exist in the pipeline executor and are used to process tasks as they are added to the queue. The number of threads here define the parallelism of gpu compute.

## H

## I

## J

## K

**Kernel** - A CUDA compute kernel.

## L

## M

**Memory Reservation** - A lease on memory. It means you are expected to be consuming that amount of memory during your execution.

**Memory Reservation Manager** - A module that can give memory reservations into one or more memory tiers. Its purpose is to be able to block executing threads from proceeding when the reservations are full utilized.

**Memory Resource** - A resource tracker which tracks the memory that has been allocated so far in a particular Pipeline Task.

## N

## O

**Operators** - Parts of the physical plan that are used to build a pipeline. Operators that can be pipelined are used to create a pipeline that then gets wrapped into a task and executed.

## P

**Pipeline** - A way of describing the transformations that a task is going to be applying to input data. It is built up by chaining the execute method of multiple operators together. Pipelines and dependencies across pipelines in a query plan is generated by DuckDB.

**Pipeline Executor** - A module that owns a local thread pool that uses GPU (via libcudf API) to execute all the operators in a Pipeline Task.

**Pipeline Task** - A task which will be executed by the pipeline executor. The task consists of a set of operators in a pipeline (generated by DuckDB) with a DataBatch associated with it.

**Pipeline Task Queue** - A task queue that stores Pipeline Tasks that are going to be processed on the GPU by Sirius using the Pipeline executor. All Pipeline executor tasks are added to this queue for execution by the operators.

## Q

## R

## S

**Scan Executor** - A module that uses DuckDB to scan data from sources and push into the Data Repository. This module will leverage DuckDB global thread pool and task scheduler.

**Scan Task** - A task which will be executed by the scan executor. The task consists of a scan range which will be generated by DuckDB

**Scan Task Queue** - A Task Queue which uses the regular DuckDB execution model for storing tasks related to scanning data into the system.

## T

## U

## V

## W

## X

## Y

## Z

---

